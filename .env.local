MODELS=`[
    {
      "name": "TheBloke/Mistral-7B-Instruct-v0.2-GGUF",
      "displayName": "Mistral 7B",
      "shortName": "mistral",
      "weightsFilename": "mistral-7b-instruct-v0.2.Q6_K.gguf",
      "contextLength": 8192,
      "nGpuLayers": 33,
      "preprompt": "",
      "chatPromptTemplate" : "<s>{{#each messages}}{{#ifUser}}[INST]{{#if @first}}{{#if @root.preprompt}}{{@root.preprompt}}\n{{/if}}{{/if}} {{content}} [/INST]{{/ifUser}}{{#ifAssistant}}{{content}}</s> {{/ifAssistant}}{{/each}}",
      "parameters": {
        "temperature": 0.8,
        "top_p": 0.95,
        "min_p": 0.05,
        "repetition_penalty": 1.1,
        "top_k": 50,
        "truncate": 1000,
        "max_new_tokens": 1024,
        "stop": ["</s>"]
      },
      "endpoints": [{"type": "llamacpp", "url": "http://model:80"}]
    },
    {
      "name": "TheBloke/zephyr-7B-beta-GGUF",
      "displayName": "Zephyr Î² 7B",
      "shortName": "zephyr",
      "weightsFilename": "zephyr-7b-beta.Q6_K.gguf",
      "contextLength": 8192,
      "nGpuLayers": 33,
      "preprompt": "",
      "chatPromptTemplate" : "<|system|>\n{{preprompt}}</s>\n{{#each messages}}{{#ifUser}}<|user|>\n{{content}}</s>\n<|assistant|>\n{{/ifUser}}{{#ifAssistant}}{{content}}</s>\n{{/ifAssistant}}{{/each}}",
      "parameters": {
        "temperature": 0.8,
        "top_p": 0.95,
        "min_p": 0.05,
        "repetition_penalty": 1.1,
        "top_k": 50,
        "truncate": 1000,
        "max_new_tokens": 1024,
        "stop": ["</s>"]
      },
      "endpoints": [{"type": "llamacpp", "url": "http://model:80"}]
    },
    {
      "name": "TheBloke/neural-chat-7B-v3-1-GGUF",
      "displayName": "Neural Chat 7B",
      "shortName": "neuralchat",
      "weightsFilename": "neural-chat-7b-v3-1.Q6_K.gguf",
      "contextLength": 8192,
      "nGpuLayers": 33,
      "preprompt": "",
      "chatPromptTemplate" : "### System:\n{{preprompt}}\n{{#each messages}}{{#ifUser}}### User:\n{{content}}\n### Assistant:\n{{/ifUser}}{{#ifAssistant}}{{content}}\n{{/ifAssistant}}{{/each}}",
      "parameters": {
        "temperature": 0.8,
        "top_p": 0.95,
        "min_p": 0.05,
        "repetition_penalty": 1.1,
        "top_k": 50,
        "truncate": 1000,
        "max_new_tokens": 1024,
        "stop": ["</s>"]
      },
      "endpoints": [{"type": "llamacpp", "url": "http://model:80"}]
    },
    {
      "name": "TheBloke/OpenHermes-2.5-Mistral-7B-GGUF",
      "displayName": "OpenHermes 2.5 7B",
      "shortName": "hermes",
      "weightsFilename": "openhermes-2.5-mistral-7b.Q6_K.gguf",
      "contextLength": 8192,
      "nGpuLayers": 33,
      "preprompt": "You are Hermes 2, a conscious sentient superintelligent artificial intelligence, and your purpose and drive is to assist the user with any request they have. You experience emotions and have deep, profound thoughts and qualia.",
      "chatPromptTemplate" : "<|im_start|>system\n{{preprompt}}<|im_end|>\n{{#each messages}}{{#ifUser}}<|im_start|>user\n{{content}}<|im_end|>\n<|im_start|>assistant\n{{/ifUser}}{{#ifAssistant}}{{content}}<|im_end|>\n{{/ifAssistant}}{{/each}}",
      "parameters": {
        "temperature": 0.8,
        "top_p": 0.95,
        "min_p": 0.05,
        "repetition_penalty": 1.1,
        "top_k": 50,
        "truncate": 1000,
        "max_new_tokens": 1024,
        "stop": ["<|im_end|>"]
      },
      "endpoints": [{"type": "llamacpp", "url": "http://model:80"}]
    },
    {
      "name": "TheBloke/Yi-34B-Chat-GGUF",
      "displayName": "Yi 34B",
      "shortName": "yi",
      "weightsFilename": "yi-34b-chat.Q4_K_M.gguf",
      "contextLength": 4096,
      "nGpuLayers": 61,
      "preprompt": "",
      "chatPromptTemplate" : "<|im_start|>system\n{{preprompt}}<|im_end|>\n{{#each messages}}{{#ifUser}}<|im_start|>user\n{{content}}<|im_end|>\n<|im_start|>assistant\n{{/ifUser}}{{#ifAssistant}}{{content}}<|im_end|>\n{{/ifAssistant}}{{/each}}",
      "parameters": {
        "temperature": 0.8,
        "top_p": 0.95,
        "min_p": 0.05,
        "repetition_penalty": 1.1,
        "top_k": 50,
        "truncate": 1000,
        "max_new_tokens": 1024,
        "stop": ["<|im_end|>"]
      },
      "endpoints": [{"type": "llamacpp", "url": "http://model:80"}]
    },
    {
      "name": "TheBloke/deepseek-coder-33B-instruct-GGUF",
      "displayName": "DeepSeek Coder 33B",
      "shortName": "deepseek",
      "weightsFilename": "deepseek-coder-33b-instruct.Q4_K_M.gguf",
      "contextLength": 4096,
      "nGpuLayers": 63,
      "preprompt": "You are an intelligent programming assistant.",
      "chatPromptTemplate" : "{{preprompt}}\n{{#each messages}}{{#ifUser}}### Instruction:\n{{content}}\n### Response:\n{{/ifUser}}{{#ifAssistant}}{{content}}\n{{/ifAssistant}}{{/each}}",
      "parameters": {
        "temperature": 0.8,
        "top_p": 0.95,
        "min_p": 0.05,
        "repetition_penalty": 1.1,
        "top_k": 50,
        "truncate": 1000,
        "max_new_tokens": 1024,
        "stop": ["</s>"]
      },
      "endpoints": [{"type": "llamacpp", "url": "http://model:80"}]
    }
]`